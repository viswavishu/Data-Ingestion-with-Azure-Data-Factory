# Data Ingestion with Azure Data Factory

## Overview

This project focuses on efficient data ingestion through batch processing using Azure Data Factory (ADF). The following Azure services were employed to achieve seamless data handling:

- **Batch Account:** Used for efficient file extraction.
- **Storage Account:** Utilized for organized data storage.
- **Azure Data Factory (ADF):** Applied for Extract, Transform, Load (ETL) operations.
- **Databricks:** Employed for data transformation processes.
- **Synapse Analytics:** Utilized for gaining valuable insights from processed data.

## Implementation

1. **Batch Processing:**
    - Utilized a batch account to efficiently handle file extraction.

2. **Data Storage:**
    - Leveraged a storage account to ensure organized and accessible data storage.

3. **ETL Operations:**
    - Implemented ETL operations seamlessly using Azure Data Factory.

4. **Data Transformation:**
    - Applied Databricks for efficient data transformation processes.

5. **Insightful Analysis:**
    - Utilized Synapse Analytics to gain valuable insights from the processed data.

## More Details

For more detailed information and code implementation, please check the [GitHub repository]([your-github-repo-link](https://github.com/viswavishu/Data-Ingestion-with-Azure-Data-Factory)https://github.com/viswavishu/Data-Ingestion-with-Azure-Data-Factory).

Feel free to explore the code and provide feedback or suggestions!
